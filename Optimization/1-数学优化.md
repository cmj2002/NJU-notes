# lecture 1
## 数学优化 (mathematical optimization)
### （数学）优化问题 (optimization problem)
可以写为以下形式：

$
\begin{array}{ll}
\operatorname{minimize} & f_{0}(x) \\
\text {subject to } & f_{i}(x) \leqslant b_{i}, \quad i=1, \cdots, m
\end{array}
$
其中：

| 符号             | 定义                                                         | 英文名                | 中文名             | 意义                             |
| ---------------- | ------------------------------------------------------------ | --------------------- | ------------------ | -------------------------------- |
| $x$              | $x=(x_1,...,x_n)$                                            | optimization variable | 优化变量           | 作出的选择(备选解)               |
| $f_0$            | $f_0:R^n\rightarrow R$                                       | objective function    | 目标函数           | 选择 $x$ 时的花费                |
| $f_i$            | $f_i:R^n\rightarrow R,\;\;\;i=1,\cdots,m$                    | constraint functions  | 约束函数           | 限制选择的条件(1)                |
| $b_1,\cdots,b_m$ |                                                              |                       | 约束上限、约束边界 | 限制选择的条件(2)                |
| $x^*$            | $f_i(x^*)\leqslant b_{i}\quad i=1, \cdots, m\\\forall z(f_i(z)\leqslant b_i \rightarrow f_0(x)\geqslant f_0(x^*))$ | optimal、solution     | 最优解、解         | 所有满足约束的备选解中花费最低的 |

minimize 和 subject to 可以分别简写为 min 和 s.t.

### 线性规划 (linear program)

$\displaystyle 
\begin{aligned}
&\forall x,y \in R^n\quad\forall \alpha,\beta\in R\\
&f_i(\alpha x+\beta y)=\alpha f_i(x)+\beta f_i(y)\quad i=0,1, \cdots, m
\end{aligned}
$

**不满足该条件的称为非线性问题 (nonlinear program)**

### 凸优化问题 (convex opitmization problem)

$\displaystyle 
\begin{aligned}
&\forall x,y \in R^n\\
&\forall \alpha,\beta\in R\quad with\;\alpha+\beta=1,\;\alpha\geqslant0,\;\beta\geqslant0 \\
&f_i(\alpha x+\beta y)\leqslant\alpha f_i(x)+\beta f_i(y)\quad i=0,1, \cdots, m
\end{aligned}
$

凸优化问题包含了线性规划问题

### 应用

#### 投资组合优化 (portfolio optimization)

求一个最佳投资方案将资本在 $n$ 种资产中进行搭配：

* $x_i$ 表示投资在第 $i$ 种资产上的资本
* $x\in R^n$ 描述资本在各个资产上的分配情况
* 约束条件：总预算限制、投资额非负（假设不允许空头）、期望收益必须大于最小可接受收益值
* $f_0(x)$ 可能是对投资回报方差（总风险）的一个度量
* 目标是在所有投资组合中选择满足所有约束条件且风险最小的组合

#### 器件尺寸问题 (device sizing)

电子设计中的器件尺寸问题，即在电子电路中设计每个器件的长度和宽度

* $x\in R^n$ 描述器件的长度和宽度
* 约束条件：多种工程上需要满足的要求，例如生产过程对器件尺寸的要求，电路在特定速度稳定运行的时间要求、电路总面积限制
* $f_0(x)$ 可能是电路总功耗
* 目标是设计合适的电路器件尺寸，使其满足设计要求并且最为节能

#### 数据拟合 (data fitting)

在一族候选模型中选择最符合观测数据和先验知识的模型

* $x\in R^n$ 为模型中的参数
* 约束条件：先验知识及参数限制（如非负性等）
* $f_0(x)$ 可能是观测数据与模型预测值之间的偏差（也可能是参数值的似然度和置信度的统计估计）
* 目标是寻找合适的模型参数值，使之符合先验知识，且偏差最小（或在统计意义上更加相似）

### 求解数学优化问题

#### 一般的数学优化问题

* 求解非常困难
* 约束条件可能非常复杂
* 变量数可能非常多
* 方法需要一些折衷（如计算时间，只能求次优解）

#### 较容易求解的优化问题

包括**最小二乘问题**、**线性规划问题**、**凸优化问题**

## 最小二乘问题 (least-squares problem)

### 问题描述

$\displaystyle minimize\quad ||Ax-b||_2^2=\sum_{i=1}^k(a_i^Tx-b_i)^2$

* $A\in R^{k\times n}$，$a_i^T$ 是 $A$ 的第 $i$ 行
* $x\in R^n$ 是优化变量

### 求解

**即求解** $\displaystyle A^{T}Ax=A^Tb$

得到**解析解** $\displaystyle x=(A^{T}A)^{-1}A^Tb$

* 最小二乘问题的解决已经有可靠而高效的算法和程序，可以认为是一个成熟的技术。
* 计算时间正比于 $n^2k(A\in R^{k\times n})$ 且比例已知
* 如果 $A$ 具有某些特殊结构（如为稀疏矩阵），计算时间可以更短
* 当规模极大或需要进行实时求解时有一定的难度(challenging)

### 使用最小二乘

#### 判断一个问题是否是最小二乘问题

* 目标函数是二次函数
* 此二次函数是半正定的

#### 加权最小二乘 (weighted least-squares)

$\displaystyle f_0(x)=\sum_{i=1}^k\omega_i(a_i^Tx-b_i)^2=\sum_{i=1}^k(\sqrt{\omega_i}a_i^Tx-\sqrt{\omega_i}b_i)^2$

$\omega_i$ 为加权系数，反映了第 $i$ 项的重要程度（对解的影响程度）

#### 正则化 (regularization)

$\displaystyle f_0(x)=\sum_{i=1}^k(a_i^Tx-b_i)^2+\rho\sum_{i=1}^kx_i^2\quad(\rho>0)$

* 此问题也可以转化为标准最小二乘问题
* 当 $x$ 的值较大时，增加的项对其施加一个惩罚，使得到的解比仅优化第一项时更切合实际
* $\rho$ 的取值由使用者决定，要使原始目标函数值尽可能小而 $\displaystyle \sum_{i=1}^kx_i^2$ 不能太大
* **当 $x$ 的分布预先知道时，可以采用正则化方法**

## 线性编程 (linear programming)

### 问题描述

minimize  $\quad c^{T} x$
subject to $\quad a_{i}^{T} x \leq b_{i}, \quad i=1, \ldots, m$
$c, a_{1}, \ldots, a_{m} \in \mathbf{R}^{n}, b_{1}, \ldots, b_{m} \in \mathbf{R}$

### 求解

* **没有解析解**
* 已经有可靠而高效的算法和程序，可以认为是一个成熟的技术
* 计算时间正比于 $n^2m(if\;\;m\geqslant n)$ ，**比例系数不好确定**
* 当具有特殊结构时需要的时间更少
* 当规模极大或需要进行实时求解时有一定的难度(challenging)

### 使用线性规划

**识别**某个问题是否可以转化为线性规划问题比最小二乘法**更复杂**，**但这也仅仅需要一些标准的技巧**，我们甚至可以通过程序半自动地识别。

#### 例：求解切比雪夫逼近问题 (chebyshev approximation problem)

minimize $\quad \max _{i=1, \cdots, k}\left|a_{i}^{T} x-b_{i}\right|$

可以转化为：

$\text{minimize   }\quad t$
$\begin{aligned} \text {subject to}\quad &a_{i}^{T} x-t \leqslant b_{i}, \quad i=1, \cdots, k \\ &-a_{i}^{T} x-t \leqslant-b_{i}, \quad i=1, \cdots, k, \end{aligned}$

## 凸优化 (convex optimization)

**核心：凸函数的局部最小值 (local minimizer) 就是（全局）最小值 (global minimizer)**

### 问题描述

$
\begin{array}{ll}
\operatorname{minimize} & f_{0}(x) \\
\text {subject to } & f_{i}(x) \leqslant b_{i}, \quad i=1, \cdots, m
\end{array}
$

其中 $f_0,f_1,\cdots ,f_m$ 是凸函数，即：

$\displaystyle 
\begin{aligned}
&\forall x,y \in R^n\\
&\forall \alpha,\beta\in R\quad with\;\alpha+\beta=1,\;\alpha\geqslant0,\;\beta\geqslant0 \\
&f_i(\alpha x+\beta y)\leqslant\alpha f_i(x)+\beta f_i(y)\quad i=0,1, \cdots, m
\end{aligned}
$

**最小二乘问题和线性规划问题是凸优化的特殊情况**

### 求解

* **没有解析解**
* 已经有可靠而高效的算法和程序（内点法较为有效），但并不是是一个成熟的技术(almost)，还处于研究阶段
* 计算时间基本(roughly)和 $max\{n^3,n^2m,F\}$ 成正比（ $F$ 是计算$f_0,f_1,\cdots ,f_m$ 的一阶导数和二阶导数所需的计算量）
* 如果问题有特殊结构（如稀疏结构），计算更快

### 使用凸优化

* 凸优化问题的**识别比较困难**，**需要更多的技巧**（相比于线性规划的识别），是具有挑战性的工作
* （surprisingly，）很多问题都可以利用凸优化求解
* （虽然有些夸张，）可以认为**如果某个实际问题可以表述为凸优化问题，那么这个问题事实上已经被解决**

#### 例：m个灯照亮n小块土地

<img src="C:\Users\10643\AppData\Roaming\Typora\typora-user-images\image-20210710225026188.png" alt="image-20210710225026188" align='left' style="zoom:33%;" />

* 第 $j$ 盏灯的功率为 $p_j$
* 第 $k$ 小块土地上的光强 $\displaystyle I_{k}=\sum_{j=1}^{m} a_{k j} p_{j}$
* 其中 $a_{k j}=r_{k j}^{-2} \max \left\{\cos \theta_{k j}, 0\right\}$

问题描述为：

$\begin{array}{cc}\min & \max _{k=1, \ldots, n}\left|\log I_{k}-\log I_{\mathrm{des}}\right| \\ \text { s.t. } & 0 \leq p_{j} \leq p_{\mathrm{max}}, j=1, \ldots, m\end{array}$

1. Use uniform power: $p_{j}=p$, vary $p$
2. Use **least-squares** $\min \sum_{i=1}^{k}\left(I_{k}-I_{\mathrm{des}}\right)^{2}=\sum_{i=1}^{k}\left(\sum_{j=1}^{m} a_{k j} p_{j}-I_{\mathrm{des}}\right)^{2}$
* Round $p_{j}$ if $p_{j}>p_{\max }$ or $p_{j}<0$
3. Use **weighted least-squares** $\min \sum_{i=1}^{k}\left(I_{k}-I_{\text {des }}\right)^{2}+\sum_{j=1}^{m} w_{j}\left(p_{j}-\frac{p_{\max }}{2}\right)^{2}$
* Adjust weights $w_{j}$ until $0 \leq p_{j} \leq p_{\text {max }}$

4. Use linear programming 

  $\min \quad \max _{k=1, \ldots, n}\left|I_{k}-I_{\mathrm{des}}\right|$
  s.t. $\quad 0 \leq p_{j} \leq p_{\max }, j=1, \ldots, m$

5. Use convex optimization

   $\displaystyle \min\quad\max_{k=1,\cdots,n}\max(\frac{I_k}{I_{des}},\frac{I_{des}}{I_k})$

   $s.t.\quad 0\leqslant p_j \leqslant p_{max},\quad j=1,\cdots,m$

## 非线性优化 (nonlinear optimization)

**指目标函数或约束函数是非线性函数，且不一定是凸函数**

**没有有效的方法**来求解一般的非线性优化问题，它甚至可能是NP难题（NP-hard）

为了求解它需要一定的折衷（compromise）

### 局部优化法 (local optimization methods)

**放弃了 $x$ 的最优性**：找到一个点 $x$ ，这个点在它周围的满足约束的点中使 $f_0(x)$ 最小

* 仅**要求目标函数和约束函数可微** (differentiability)
* 快速，可解决大规模问题
* **初始值的选取 (initial guess) 对求解结果有很大影响**
* **无法估计局部最优解与全局最优解的差距**
* 对参数值敏感
* 更多地是一项艺术（或技巧）而非一项技术

| 方法       | 问题转化 (problem formulation) | 问题的解决 |
| ---------- | ------------------------------ | ---------- |
| 凸优化     | **art**                        | standard   |
| 局部优化法 | straightforward                | **art**    |

### 全局优化

寻找全局最优解，**牺牲了效率**

**求解的复杂性随问题规模（$n,m$）呈指数增长** (grows exponentially)

对于变量个数较少的**小规模**问题、若对**计算时间没有苛刻的要求**且寻找**全局最优解非常有价值**，我们采用全局优化

例：工程中高价值系统或安全性第一系统的**最坏情况分析**或**验证问题**

* $x$ 是环境的参数，在实际生产中随工作环境和工作点改变
* 目标函数是效用函数，函数值越小，情况越坏
* 寻找最坏情况下的参数值（最差值）
* 若在最差值下系统仍可靠运行，我们认为系统是安全的或者是可靠的
* 局部优化可以迅速找到较差值，但不能保证是最差值
* 如果验证系统可靠非常有价值，或者不可靠（不安全）的代价非常大，全局优化是有必要的

### 在非凸问题中运用凸优化

* **为局部优化选取初始值**。将非凸问题近似为凸优化问题，将其精确解作为非凸问题的局部优化算法的初始值、
* **非凸优化中的凸启发式算法**（Convex heuristics for nonconvex optimization）
* **给出全局优化的下界**（Bounds for global optimization）。包括**松弛算法**（Relaxation），**Lagrange松弛**（Lagrangian relaxation）

