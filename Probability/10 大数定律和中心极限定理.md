# 10 大数定律和中心极限定理

## 大数定律

考：四大大数定理是什么，背下来

给定随机变量 $X_{1}, X_{2}, \cdots, X_{n}$, 这些随机变量的均值 (算术平均值) 为
$$
\frac{1}{n} \sum_{i=1}^{n} X_{i}
$$
当 $n$ 非常大时, 大数定律考虑随机变量的均值是否具有稳定性.

### 定义

#### 依概率收敛

设 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 是一随机变量序列, $a$ 是一常数, 如果对任意 $\epsilon>0$ 有
$$
\lim _{n \rightarrow \infty} \operatorname{Pr}\left\{\left|X_{n}-a\right|<\epsilon\right\}=1 \text { 或 } \lim _{n \rightarrow \infty} \operatorname{Pr}\left\{\left|X_{n}-a\right|>\epsilon\right\}=0
$$
则称随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 依概率收敛于 $a$, 记 $X_{n} \stackrel{P}{\rightarrow} a$

与数列收敛不一样的是：依概率收敛的数列是不确定的

下面我们给出依概率收敛的性质:

1) 若 $X_{n} \stackrel{P}{\rightarrow} a$ 且函数 $g: \mathbb{R} \rightarrow \mathbb{R}$ 在 $X=a$ 点连续, 则 $g\left(X_{n}\right) \stackrel{P}{\rightarrow} g(a)$.
2) 若 $X_{n} \stackrel{P}{\rightarrow} a, Y_{n} \stackrel{P}{\rightarrow} b$, 函数 $g: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ 在点 $(X, Y)=(a, b)$ 处连续, 则 $g\left(X_{n}, Y_{n}\right) \stackrel{P}{\rightarrow} g(a, b)$.
例如: 如果 $X_{n} \stackrel{P}{\rightarrow} a$ 和 $Y_{n} \stackrel{P}{\rightarrow} b$, 那么 $X_{n}+Y_{n} \stackrel{P}{\rightarrow} a+b$ 和 $X_{n} Y_{n} \stackrel{P}{\rightarrow} a b$ 

### 大数定律

若随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 满足
$$
\frac{1}{n} \sum_{i=1}^{n} X_{i} \stackrel{P}{\rightarrow} \frac{1}{n} \sum_{i=1}^{n} E\left[X_{i}\right]
$$
则称 $\left\{X_{n}\right\}$ 服从大数定律

大数定理刻画了随机变量的均值 (算术平均值) 依概率收敛于期望的均值 (算术平均值)

下面介绍几种大数定律

#### 马尔可夫 Markov 大数定律

如果随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 满足
$$
\frac{1}{n^{2}} \operatorname{Var}\left(\sum_{i=1}^{n} X_{i}\right) \rightarrow 0 \quad n \rightarrow \infty
$$
则 $\left\{X_{n}\right\}$ 服从大数定律

马尔可夫大数定律不要求随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立或同分布, 其证明直接通过 Chebyshev 不等式有
$$
\operatorname{Pr}\left[\left|\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-E\left[X_{i}\right]\right)\right| \geqslant \epsilon\right] \leqslant \frac{1}{n^{2} \epsilon^{2}} \operatorname{Var}\left(\sum_{i=1}^{n} X_{i}\right) \rightarrow 0 \quad n \rightarrow \infty
$$
#### 切比雪夫 Chebyshev 大数定律

设随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ **相互独立**, **且存在常数** $c>0$ 使得 $\operatorname{Var}\left(X_{n}\right) \leqslant c$, 则 $\left\{X_{n}\right\}$ 服从大数定律

此处独立的随机变量可以修改为'不相关随机变量'

证明直接通过切比雪夫不等式
$$
\operatorname{Pr}\left[\left|\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-E\left[X_{i}\right]\right)\right| \geqslant \epsilon\right] \leqslant \frac{1}{\epsilon^{2} n^{2}} \operatorname{Var}\left(\sum_{i=1}^{n} X_{i}\right) \leqslant \frac{c}{n \epsilon^{2}} \rightarrow 0 \quad n \rightarrow \infty
$$
#### 辛钦 Khintchine 大数定律

设 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 为独立同分布随机变量序列, 且每个随机变量的期望 $E\left[X_{i}\right]=\mu$ 存在, 则 $\left\{X_{n}\right\}$ 服从大数定律

辛钦大数定律**不要求方差一定存在**, 其证明超出了本书范围

#### Bernoulli大数定律

设随机变量序列 $X_{n} \sim B(n, p)(p>0)$, 对任意 $\epsilon>0$ 有
$$
\lim _{n \rightarrow \infty} \operatorname{Pr}\left[\left|\frac{X_{n}}{n}-p\right| \geqslant \epsilon\right]=0
$$
即 $X_{n} / n \stackrel{P}{\rightarrow} p$

定理的证明依据二项分布的性质：独立同分布随机变量 $Y_{1}, Y_{2}, \ldots, Y_{n}$ 满足 $Y_{i} \sim \operatorname{Ber}(p)$, 则
$$
X_{n}=\sum_{i=1}^{n} Y_{i} \sim \mathrm{B}(n, p)
$$
于是得到
$$
\lim _{n \rightarrow \infty} \operatorname{Pr}\left[\left|\frac{X_{n}}{n}-p\right| \geqslant \epsilon\right]=\lim _{n \rightarrow \infty} \operatorname{Pr}\left[\left|\frac{1}{n} \sum_{i=1}^{n} Y_{i}-E\left[Y_{i}\right]\right| \geqslant \epsilon\right] \leqslant \frac{1}{\epsilon^{2} n^{2}} \operatorname{Var}\left(\sum_{i=1}^{n} Y_{i}\right)=\frac{p(1-p)}{\epsilon^{2} n} \rightarrow 0
$$
如何判断随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 满足大数定律:
- 若随机变量独立同分布, 则利用辛钦大数定律查看期望是否存在;
- 对非独立同分布随机变量, 则利用 Markov 大数定律判断方差是否趋于零.

**[例]**

独立的随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 满足 $\operatorname{Pr}\left\{X_{n}=n^{1 / 4}\right\}=\operatorname{Pr}\left\{X_{n}=-n^{1 / 4}\right\}=$ 1/2. 证明 $\left\{X_{n}\right\}$ 服从大数定律

**证明** 根据题意可得 $E\left[X_{i}\right]=0$, 以及 $\operatorname{Var}\left(X_{i}\right)=E\left[X_{i}^{2}\right]=i^{1 / 2}$, 根据 Chebyshev 不等式和独立性有
$$
\operatorname{Pr}\left[\left|\frac{1}{n} \sum_{i=1}^{n} X_{i}\right| \geqslant \epsilon\right] \leqslant \frac{1}{n^{2} \epsilon^{2}} \operatorname{Var}\left(\sum_{i=1}^{n} X_{i}\right)=\frac{1}{n^{2} \epsilon^{2}} \sum_{i=1}^{n} \operatorname{Var}\left(X_{i}\right)=\frac{1}{\epsilon^{2}} \frac{1}{n^{2}} \sum_{i=1}^{n} i^{1 / 2} \leqslant \frac{1}{\epsilon^{2} \sqrt{n}}
$$
再根据
$$
\sum_{i=1}^{n} i^{1 / 2} \leqslant \sum_{i=1}^{n} \int_{i}^{i+1} i^{1 / 2} d x \leqslant \sum_{i=1}^{n} \int_{i}^{i+1} x^{1 / 2} d x=\int_{1}^{n+1} x^{1 / 2} d x=2\left((n+1)^{3 / 2}-1\right) / 3
$$
由此可得当 $n \rightarrow+\infty$ 时有
$$
\operatorname{Pr}\left[\left|\frac{1}{n} \sum_{i=1}^{n} X_{i}\right| \geqslant \epsilon\right] \leqslant \frac{2\left((n+1)^{3 / 2}-1\right) / 3}{\epsilon^{2} n^{2}} \rightarrow 0
$$
### 小结

- Markov 大数定律: 若随机变量序列 $\left\{X_{i}\right\}$ 满足 $\operatorname{Var}\left(\sum_{i=1}^{n} X_{n}\right) / n^{2} \rightarrow 0$, 则满足大数定律;
- Chebyshev 大数定律: 若独立随机变量序列 $\left\{X_{i}\right\}$ 满足 $\operatorname{Var}\left(X_{i}\right) \leqslant c$, 则满足大数定律;
- Khintchine 大数定律: 若独立同分布随机变量序列 $\left\{X_{i}\right\}$ 期望存在, 则满足大数定律;
- Bernoulli 大数定律: 对二项分布 $X_{n} \sim \mathrm{B}(n, p)$. 有 $X_{n} / n \stackrel{P}{\rightarrow} p$

## 中心极限定理

例题见24讲讲义

大数定理：$n\to +\infty$ 时平均值 $\displaystyle \frac{1}{n}\sum_{i=1}^n X_i$ 的趋势

中心极限定理：$n\to +\infty$ 时平均值 $\displaystyle \frac{1}{n}\sum_{i=1}^n X_i$ 的具体分布

前面讨论的是 $\displaystyle \frac{1}{n}\sum_{i=1}^n X_i$ 在 $n\to +\infty$ 的值，现在讨论其分布

对独立的随机变量序列 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$, 我们考虑标准化后随机变量
$$
Y_{n}=\frac{\sum_{i=1}^{n} X_{i}-\sum_{i=1}^{n} E\left(X_{i}\right)}{\sqrt{\operatorname{Var}\left(\sum_{i=1}^{n} X_{i}\right)}}
$$
的极限分布是否为服从正态分布. 首先介绍依分布收敛

### 依分布收敛

定义 $7.2$ 设随机变量 $Y$ 的分布函数为 $F_{Y}(y)=\operatorname{Pr}(Y \leqslant y)$, 以及随机变量序列 $Y_{1}, Y_{2}, \cdots, Y_{n}, \cdots$ 的分布函数分别为 $F_{Y_{n}}(y)=\operatorname{Pr}\left(Y_{n} \leqslant y\right)$, 如果
$$
\lim _{n \rightarrow \infty} \operatorname{Pr}\left[Y_{n} \leqslant y\right]=\operatorname{Pr}[Y \leqslant y] \text {, 即 } \lim _{n \rightarrow \infty} F_{Y_{n}}(y)=F_{Y}(y) \text {, }
$$
则称随机变量序列 $Y_{1}, Y_{2}, \cdots, Y_{n}, \cdots$ 依分布收敛于 $Y$, 记 $Y_{n} \stackrel{d}{\rightarrow} Y$

### 独立同分布中心极限定理

下面介绍独立同分布中心极限定理, 又被称为林德贝格-勒维 (Lindeberg-Lévy) 中心极限定理"

设独立同分布的随机变量 $X_1,\cdots,X_n,\cdots$ 的期望 $E(X_1)=\mu$ 和方差 $Var(X_1)=\sigma^2$ ，则：
$$
Y_n=\frac{\sum_{i=1}^n X_i-n\mu}{\sigma\sqrt{n}}\stackrel{d}{\rightarrow}N(0,1)
$$
前面介绍过标准正态分布的分布函数 $\Phi$，那么上式等价于：
$$
\lim_{n\to+\infty}P[Y_n\leq y]=\Phi(y)
$$

### 棣莫弗-拉普拉斯中心极限定理

设随机变量 $X_{n} \sim B(n, p)$, 则
$$
Y_{n}=\frac{X_{n}-n p}{\sqrt{n p(1-p)}} \stackrel{d}{\rightarrow} \mathcal{N}(0,1)
$$
由此中心极限定理可知: 当 $n$ 非常大时随机变量 $X_{n} \sim B(n, p)$ 满足 $X_{n} \stackrel{\text { 近似 }}{\sim} \mathcal{N}(n p, n p(1-p))$, 从而 有如下近似估计:
$$
\operatorname{Pr}\left[X_{n} \leqslant y\right]=\operatorname{Pr}\left[\frac{X_{n}-n p}{\sqrt{n p(1-p)} \leqslant \frac{y-n p}{\sqrt{n p(1-p)}}}\right] \approx \Phi\left(\frac{y-n p}{\sqrt{n p(1-p)}}\right) .
$$
针对上式, 可以考虑三种问题:

1. 已知 $n$ 和 $\operatorname{Pr}\left[X_{n} \leqslant y\right]$, 求 $y$;
2. 已知 $n$ 和 $y$, 求 $\operatorname{Pr}\left[X_{n} \leqslant y\right]$;
3. 已知 $y$ 和 $\operatorname{Pr}\left[X_{n} \leqslant y\right]$, 求 $n$.

### 李雅普诺夫 (Lyapunov) 中心极限定理：

**不需要同分布**

设独立随机变量 $X_{1}, X_{2}, \ldots, X_{n}, \ldots$ 的期望 $E\left[X_{n}\right]=\mu_{n}$ 和方差 $\operatorname{Var}\left(X_{n}\right)=\sigma_{n}^{2}>0$

记 $B_{n}^{2}=\sum_{k=1}^{n} \sigma_{k}^{2}$,

若存在 $\delta>0$, 当 $n \rightarrow \infty$ 时有
$$
\frac{1}{B_{n}^{2+\delta}} \sum_{k=1}^{n} E\left[\left|X_{k}-\mu_{k}\right|^{2+\delta}\right] \rightarrow 0
$$
成立, 则有
$$
Y_{n}=\frac{\sum_{k=1}^{n} X_{k}-\sum_{k=1}^{n} E\left(X_{k}\right)}{\sqrt{\operatorname{Var}\left(\sum_{k=1}^{n} X_{k}\right)}} \stackrel{d}{\rightarrow} \mathcal{N}(0,1)
$$
### 中心极限定理小结

- 独立同分布中心极限定理: 若 $E\left[X_{k}\right]=\mu$ 和 $\operatorname{Var}\left(X_{k}\right)=\sigma^{2}$, 则 $\sum_{k=1}^{n} X_{k} \stackrel{d}{\rightarrow} \mathcal{N}\left(n \mu, n \sigma^{2}\right)$;
- 棣莫弗-拉普拉斯中心极限定理: 若 $X_{k} \sim B(k, p)$, 则 $X_{k} \stackrel{d}{\rightarrow} \mathcal{N}(n p, n p(1-p))$;
- **独立不同分布**中心极限定理: 李雅普诺夫定理.